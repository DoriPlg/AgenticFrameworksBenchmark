version: '3.8'

services:
  gaia-agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: gaia-agent
    environment:
      # Pass through environment variables for API keys
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST}
      # HuggingFace token for GAIA dataset access
      - HF_TOKEN=${HF_TOKEN}
      # Add any other environment variables your llmforall.py needs
    volumes:
      # Mount data directory for GAIA test files
      - ./data:/app/data:ro
      # Optional: Mount output directory for results
      - ./output:/app/output
      # CrewAI storage (needs write access)
      - crewai-storage:/home/gaiauser/.local/share/crewai
      # HuggingFace cache for GAIA dataset
      - hf-cache:/home/gaiauser/.cache/huggingface
    networks:
      - gaia-network
    # Resource limits for security
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 512M
    # Prevent container from running as root
    user: "1000:1000"
    # Security options
    security_opt:
      - no-new-privileges:true
    # Tmpfs for temporary files
    tmpfs:
      - /tmp
      - /home/gaiauser/.cache

volumes:
  crewai-storage:
    driver: local
  hf-cache:
    driver: local

networks:
  gaia-network:
    driver: bridge
